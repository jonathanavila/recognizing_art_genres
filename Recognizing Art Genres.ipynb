{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "447ee99cafbd87bc963f88ab60bf1127c0590e51"
   },
   "source": [
    "**Run this to delete the entire filesystem**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5c1f0cfa31df143e579eae29effbf8d9b96c054c"
   },
   "outputs": [],
   "source": [
    "# import shutil\n",
    "\n",
    "# shutil.rmtree('test/')\n",
    "# shutil.rmtree('train/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "da7eb371ac1a4b957fcce73a59fe2742967e3d56",
    "scrolled": true
   },
   "source": [
    "**Import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "78a8d0f4b0e11915fb3d7c238eaed9c7f5361610"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "# print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "from shutil import copy2\n",
    "\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "from scipy.stats import itemfreq\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns # visualizations\n",
    "\n",
    "import random # for setting seed\n",
    "\n",
    "import IPython\n",
    "\n",
    "import tensorflow\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "# from confusion_matrix import plot_confusion_matrix\n",
    "# from plot_history import plot\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "from keras import metrics\n",
    "import keras.backend as K\n",
    "from tensorflow.python.keras.applications import ResNet50\n",
    "from tensorflow.python.keras.applications import VGG16\n",
    "\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n",
    "\n",
    "from tensorflow.python.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "## Functions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "196f501fbf4e9911f01775895ce570fe6ce7b8ad"
   },
   "outputs": [],
   "source": [
    "\n",
    "def precision(y_true, y_pred):\n",
    "\n",
    "    # Count positive samples.\n",
    "    c1 = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    c2 = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    c3 = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "\n",
    "    # If there are no true samples, fix the F1 score at 0.\n",
    "    if c3 == 0:\n",
    "        return 0\n",
    "\n",
    "    # How many selected items are relevant?\n",
    "    precision = c1 / c2\n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    # Count positive samples.\n",
    "    c1 = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    c2 = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    c3 = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "\n",
    "    # If there are no true samples, fix the F1 score at 0.\n",
    "    if c3 == 0:\n",
    "        return 0\n",
    "\n",
    "    # How many relevant items are selected?\n",
    "    recall = c1 / c3\n",
    "    return recall\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "\n",
    "    # Count positive samples.\n",
    "    c1 = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    c2 = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    c3 = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "\n",
    "    # If there are no true samples, fix the F1 score at 0.\n",
    "    if c3 == 0:\n",
    "        return 0\n",
    "\n",
    "    # How many selected items are relevant?\n",
    "    precision = c1 / c2\n",
    "\n",
    "    # How many relevant items are selected?\n",
    "    recall = c1 / c3\n",
    "\n",
    "    # Calculate f1_score\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return f1_score\n",
    "\n",
    "def topk(y_true, y_pred):\n",
    "    return metrics.top_k_categorical_accuracy(y_true, y_pred, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot training & validation accuracy values\n",
    "def plot(history):\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "840003a44c6882a988d9cd6263b4155c86b11ca0"
   },
   "source": [
    "# Goal: Create a model that can identify an genre given a painting from the [\"Painter By Numbers\" dataset](https://www.kaggle.com/c/painter-by-numbers)\n",
    "\n",
    "# Methods / Tools\n",
    "1. [Keras](https://keras.io/)\n",
    "2. [Tensorflow](https://www.tensorflow.org/)\n",
    "3. [ResNet50 & VGG]\n",
    "  * a Convolutional Neural Network (CNN) model instance in Keras\n",
    "4. [Transfer Learning](https://www.kaggle.com/dansbecker/transfer-learning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a47f3f2ae34da5c3ff3747a21b7a5c7752e9c4bb"
   },
   "source": [
    "# Set a random seed and get environment info for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "203e70c989b48533a3f4cf3ba0cd8982730700ae"
   },
   "outputs": [],
   "source": [
    "my_seed = 42 # 480 could work too\n",
    "random.seed(my_seed)\n",
    "np.random.seed(my_seed)\n",
    "tensorflow.set_random_seed(my_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "041e25c9e1294a3b4b60d562af7c1ca64c3b955d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'commit_hash': '7f10f7bb3',\n",
      " 'commit_source': 'installation',\n",
      " 'default_encoding': 'UTF-8',\n",
      " 'ipython_path': '/opt/conda/lib/python3.6/site-packages/IPython',\n",
      " 'ipython_version': '6.4.0',\n",
      " 'os_name': 'posix',\n",
      " 'platform': 'Linux-4.9.0-5-amd64-x86_64-with-debian-9.4',\n",
      " 'sys_executable': '/opt/conda/bin/python',\n",
      " 'sys_platform': 'linux',\n",
      " 'sys_version': '3.6.6 |Anaconda, Inc.| (default, Oct  9 2018, 12:34:16) \\n'\n",
      "                '[GCC 7.3.0]'}\n"
     ]
    }
   ],
   "source": [
    "# print system information (but not packages)\n",
    "print(IPython.sys_info())\n",
    "\n",
    "# get module information\n",
    "!pip freeze > frozen-requirements.txt\n",
    "\n",
    "# append system information to file\n",
    "with open(\"frozen-requirements.txt\", \"a\") as file:\n",
    "    file.write(IPython.sys_info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a16ec52a1a5d9cb7d5d956d69b4fd0886aa1812e"
   },
   "source": [
    "# Info about ResNet50 & VGG on Keras\n",
    "### arguments:\n",
    "* \"The default **input** size for this model is **224x224**.\"\n",
    "* \"**input_tensor**: optional Keras tensor (i.e. output of layers.Input()) to use as image input for the model.\"\n",
    "* \"**classes**: optional number of classes to classify images into, only to be specified if include_top is  True, and if no weights argument is specified.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0d6f5ebba9e9f1ea752fa222262e110af8404739"
   },
   "source": [
    "# Read in CSV File, Filter to only get top 9 genres, split into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "cbf4af47d23674d1c40e21c1b057da416d123cd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 79433 paintings inside train_csv\n"
     ]
    }
   ],
   "source": [
    "data_dir = '../input/processed-data/train_processed/'\n",
    "train_dir = data_dir + 'train/'\n",
    "df = pd.read_csv('../input/painter-by-numbers/train_info.csv')\n",
    "print(\"there are \" + str(df.shape[0]) + \" paintings inside train_csv\") \n",
    "df['genre'] = df['genre'].apply(lambda x: 'nude' if x == 'nude painting (nu)' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "d50a877ed4affa763764a658dae73def6b40e95f"
   },
   "outputs": [],
   "source": [
    "#filter genre_data\n",
    "genre = ['portrait', 'landscape', 'genre painting', 'abstract', 'religious painting', 'cityscape', 'sketch and study', 'illustration', 'still life']\n",
    "genre_data = df[df['genre'].isin(genre)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "ebbd5f24b34fd4a6643d743cc604b81a7a907f75"
   },
   "outputs": [],
   "source": [
    "genre_train_data, genre_test_data = train_test_split(genre_data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b59785953d6cebed83f6dfe6efabd153c4a01c2c"
   },
   "source": [
    "# Create working directories for genres "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": false,
    "_uuid": "4ca51a54188b499d2a1d27c00e73e19400798b6b"
   },
   "outputs": [],
   "source": [
    "working_train_dir = \"train/\"\n",
    "working_test_dir = \"test/\"\n",
    "if (os.path.isdir(working_train_dir) == False):\n",
    "    os.mkdir(working_train_dir)\n",
    "    print(\"created \" + working_train_dir)\n",
    "else:\n",
    "    print(working_train_dir + \" exists\")\n",
    "    \n",
    "if (os.path.isdir(working_test_dir) == False):\n",
    "    os.mkdir(working_test_dir)\n",
    "    print(\"created \" + working_test_dir)\n",
    "else:\n",
    "    print(working_test_dir + \" exists\")\n",
    "\n",
    "for genre in genre:\n",
    "    train_genre_dir = working_train_dir + genre\n",
    "    if (os.path.isdir(train_genre_dir) == False):\n",
    "        os.mkdir(train_genre_dir)\n",
    "        print(\"created \" + train_genre_dir)\n",
    "    else:\n",
    "        print(train_genre_dir + \" exists\")\n",
    "        \n",
    "    test_genre_dir = working_test_dir + genre\n",
    "    if (os.path.isdir(test_genre_dir) == False):\n",
    "        os.mkdir(test_genre_dir)\n",
    "        print(\"created \" + test_genre_dir)\n",
    "    else:\n",
    "        print(test_genre_dir + \" exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "56fbdf1051bdf754e050cd68928490449c57125f"
   },
   "source": [
    "# Copy pre-processed photos into training and test direcs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": false,
    "_uuid": "c664196cc6f9cf238ec503bc3d8ea63586ca8d55"
   },
   "outputs": [],
   "source": [
    "i=0\n",
    "for _, row in genre_train_data.iterrows():\n",
    "    f = row['filename']\n",
    "    g = row['genre']\n",
    "    if (os.path.exists(train_dir+f) and not os.path.exists(working_train_dir+g+'/'+f)):\n",
    "        # print()\n",
    "        copy2(train_dir+f, working_train_dir+g)\n",
    "        i += 1\n",
    "\n",
    "print(\"\\ncopied train__data \" + str(i))\n",
    "\n",
    "i=0\n",
    "for _, row in genre_test_data.iterrows():\n",
    "    f = row['filename']\n",
    "    g = row['genre']\n",
    "    if (os.path.exists(train_dir+f) and not os.path.exists(working_test_dir+g+'/'+f)):\n",
    "        copy2(train_dir+f, working_test_dir+g)\n",
    "        i += 1\n",
    "\n",
    "print(\"\\ncopied test_data \" + str(i))\n",
    "\n",
    "\n",
    "steps_per_epoch = 752\n",
    "validation_steps = 188"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f432bc3fb7c05a36a6e7de7b706be398bcacb006"
   },
   "source": [
    "# Create data generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6debca85540fd6285fd2ec3836d498b52cc1c96a"
   },
   "outputs": [],
   "source": [
    "image_size_224 = 224\n",
    "\n",
    "data_generator_224_no_aug = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input)\n",
    "\n",
    "train_generator_224_no_aug = data_generator_224_no_aug.flow_from_directory(\n",
    "        working_train_dir,\n",
    "        target_size=(image_size_224, image_size_224),\n",
    "        batch_size=64,\n",
    "        class_mode='categorical', \n",
    "        shuffle=False)\n",
    "\n",
    "validation_generator_224_no_aug = data_generator_224_no_aug.flow_from_directory(\n",
    "        working_test_dir,\n",
    "        target_size=(image_size_224, image_size_224),\n",
    "        batch_size=64,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "\n",
    "print(\"\\n\\nmodel - train_generator_no_aug\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "dffba67dcfa671ed90e73b03e765a58a88531711"
   },
   "outputs": [],
   "source": [
    "data_generator_224_aug = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip = True)\n",
    "\n",
    "train_generator_224_aug = data_generator_224_aug.flow_from_directory(\n",
    "        working_train_dir,\n",
    "        target_size=(image_size_224, image_size_224),\n",
    "        batch_size=64,\n",
    "        class_mode='categorical', \n",
    "        shuffle=False)\n",
    "\n",
    "validation_generator_224_aug = data_generator_224_aug.flow_from_directory(\n",
    "        working_test_dir,\n",
    "        target_size=(image_size_224, image_size_224),\n",
    "        batch_size=64,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(os.listdir(working_test_dir)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_cnn_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(224, 224, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # the model so far outputs 3D feature maps (height, width, features)\n",
    "\n",
    "    model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(9))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(lr=1e-3, decay=1e-3, momentum=0.9),\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "cnn_model = basic_cnn_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_history = cnn_model.fit_generator(\n",
    "        train_generator_224_aug,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        epochs=50,\n",
    "        validation_data=validation_generator_224_aug,\n",
    "        validation_steps= validation_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_notop_path_vgg = '../input/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg_no_aug = Sequential()\n",
    "\n",
    "# now let's set up the first layers\n",
    "model_vgg_no_aug.add(VGG16(    # add a whole ResNet50 model\n",
    "  include_top=False,          # without the last layer\n",
    "  weights=weights_notop_path_vgg, # and with the \"notop\" weights file\n",
    "  pooling='avg' # means collapse extra \"channels\" into 1D tensor by taking an avg across channels\n",
    "))\n",
    "\n",
    "# Now lets add a \"Dense\" layer to make predictions\n",
    "model_vgg_no_aug.add(Dense(\n",
    "  num_classes, # this last layer just has 2 nodes\n",
    "  activation='softmax' # apply softmax function to turn values of this layer into probabilities\n",
    "))\n",
    "\n",
    "model_vgg_no_aug.layers[0].trainable = False\n",
    "\n",
    "model_vgg_no_aug.compile(\n",
    "  optimizer='sgd', # stochastic gradient descent (how to update Dense connections during training)\n",
    "  loss='categorical_crossentropy', # aka \"log loss\" -- the cost function to minimize \n",
    "  # so 'optimizer' algorithm will minimize 'loss' function\n",
    "  metrics=['accuracy', f1_score, topk, recall, precision] # ask it to report % of correct predictions\n",
    ")\n",
    "print(\"Compiled layer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_vgg_no_aug = model_vgg_no_aug.fit_generator(\n",
    "        train_generator_224_no_aug,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        epochs=50, # so... total of 9 epochs?\n",
    "        validation_data=validation_generator_224_no_aug,\n",
    "        validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(history_vgg_no_aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg_aug = Sequential()\n",
    "\n",
    "# now let's set up the first layers\n",
    "model_vgg_aug.add(VGG16(    # add a whole ResNet50 model\n",
    "  include_top=False,          # without the last layer\n",
    "  weights=weights_notop_path_vgg, # and with the \"notop\" weights file\n",
    "  pooling='avg' # means collapse extra \"channels\" into 1D tensor by taking an avg across channels\n",
    "))\n",
    "\n",
    "# Now lets add a \"Dense\" layer to make predictions\n",
    "model_vgg_aug.add(Dense(\n",
    "  num_classes, # this last layer just has 2 nodes\n",
    "  activation='softmax' # apply softmax function to turn values of this layer into probabilities\n",
    "))\n",
    "\n",
    "model_vgg_aug.layers[0].trainable = False\n",
    "\n",
    "model_vgg_aug.compile(\n",
    "  optimizer='sgd', # stochastic gradient descent (how to update Dense connections during training)\n",
    "  loss='categorical_crossentropy', # aka \"log loss\" -- the cost function to minimize \n",
    "  # so 'optimizer' algorithm will minimize 'loss' function\n",
    "  metrics=['accuracy', f1_score, topk, recall, precision] # ask it to report % of correct predictions\n",
    ")\n",
    "print(\"Compiled layer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_vgg_aug = model_vgg_no_aug.fit_generator(\n",
    "        train_generator_224_aug,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        epochs=50, # so... total of 9 epochs?\n",
    "        validation_data=validation_generator_224_aug,\n",
    "        validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(history_vgg_aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fb71dd2152115a8189afe83f0bf7c835544eec71"
   },
   "source": [
    "# ResNet50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e42b4a1f9340e962c9330796cb917916165385ad"
   },
   "source": [
    "## Specify Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ab92522e19ef9396b11f5922c020e12d74d59217"
   },
   "outputs": [],
   "source": [
    "weights_notop_path = '../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non Augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rs_no_aug = Sequential()\n",
    "\n",
    "# now let's set up the first layers\n",
    "model_rs_no_aug.add(ResNet50(    # add a whole ResNet50 model\n",
    "  include_top=False,          # without the last layer\n",
    "  weights=weights_notop_path, # and with the \"notop\" weights file\n",
    "  pooling='avg' # means collapse extra \"channels\" into 1D tensor by taking an avg across channels\n",
    "))\n",
    "\n",
    "# Now lets add a \"Dense\" layer to make predictions\n",
    "model_rs_no_aug.add(Dense(\n",
    "  num_classes, # this last layer just has 2 nodes\n",
    "  activation='softmax' # apply softmax function to turn values of this layer into probabilities\n",
    "))\n",
    "\n",
    "model_rs_no_aug.layers[0].trainable = False\n",
    "\n",
    "model_rs_no_aug.compile(\n",
    "  optimizer='sgd', # stochastic gradient descent (how to update Dense connections during training)\n",
    "  loss='categorical_crossentropy', # aka \"log loss\" -- the cost function to minimize \n",
    "  # so 'optimizer' algorithm will minimize 'loss' function\n",
    "  metrics=['accuracy', f1_score, topk, recall, precision] # ask it to report % of correct predictions\n",
    ")\n",
    "print(\"Compiled layer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_resnet_no_aug = model_rs_no_aug.fit_generator(\n",
    "        train_generator_224_no_aug,\n",
    "        steps_per_epoch=200,\n",
    "        epochs=50, \n",
    "        validation_data=validation_generator_224_no_aug,\n",
    "        validation_steps=80)\n",
    "print(\"history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(history_resnet_no_aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "332170d1bce551927c33f3cb628c9ac86abd577b"
   },
   "outputs": [],
   "source": [
    "model_rs_aug = Sequential()\n",
    "\n",
    "# now let's set up the first layers\n",
    "model_rs_aug.add(ResNet50(    # add a whole ResNet50 model\n",
    "  include_top=False,          # without the last layer\n",
    "  weights=weights_notop_path, # and with the \"notop\" weights file\n",
    "  pooling='avg' # means collapse extra \"channels\" into 1D tensor by taking an avg across channels\n",
    "))\n",
    "\n",
    "# Now lets add a \"Dense\" layer to make predictions\n",
    "model_rs_aug.add(Dense(\n",
    "  num_classes, # this last layer just has 2 nodes\n",
    "  activation='softmax' # apply softmax function to turn values of this layer into probabilities\n",
    "))\n",
    "\n",
    "model_rs_aug.layers[0].trainable = False\n",
    "\n",
    "model_rs_aug.compile(\n",
    "  optimizer='sgd', # stochastic gradient descent (how to update Dense connections during training)\n",
    "  loss='categorical_crossentropy', # aka \"log loss\" -- the cost function to minimize \n",
    "  # so 'optimizer' algorithm will minimize 'loss' function\n",
    "  metrics=['accuracy', f1_score, topk, recall, precision] # ask it to report % of correct predictions\n",
    ")\n",
    "print(\"Compiled layer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_resnet_aug = model_rs_aug.fit_generator(\n",
    "        train_generator_224_aug,\n",
    "        steps_per_epoch=200,\n",
    "        epochs=50, \n",
    "        validation_data=validation_generator_224_aug,\n",
    "        validation_steps=80)\n",
    "print(\"history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(history_resnet_aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9c1fa213c61cd348b31e8d91e42e05b439e10458"
   },
   "outputs": [],
   "source": [
    "Y_pred = model_rs_no_aug.predict_generator(validation_generator_224_no_aug)\n",
    "Y_trues = validation_generator_224_no_aug.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c29b8eca3816617b2a3fb76130e41a4f4064477f"
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(Y_pred, Y_trues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2bfdaa80ce7c70310835e6fe4c789bbd7978c7a4"
   },
   "source": [
    "plot_confusion_matrix(cm, genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c75affcd0224baf0e006e0cb12a4785fc84a4d1a"
   },
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dc1f6d90f1ad532978b1b76db8f39019a7b1ed99"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "51b4b1c67b5c0747c3b2ed8691ddad26eb22ab6b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c4fbf49a2522761558dc85dd177ed35760e24e23"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "52bbc0bcb82ba0b7b7f65337dfa29a8351588429"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "aa6c4e971fb52cc35b5e0642b2e73e422280b582"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8bad08d46f73dcc9e7151adca8780a143d9ce89f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c9495da36a2d095fa152b046251489f66e6f10ba"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "657cd30277eec74c56181b01a303fc0361580154"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "829ed498ced8b2e6dc556768c786e1f526b003ba"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1088feafba90844ff866ebaa97a0d0afe4293f8d"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "332f3c6958bf6c4181bbffb960e8cc1f9a85020a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "56d3f645ba06c584d0447f961628895e232aba50"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fa7f111e5ec7456dc1e35096d22047fbfa10dd7a"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f76594a6f7fdc6fba320ff71402285ec6cc89640"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "41d7c1f185a7112fd09c89d51dbad8a9aee2c429"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "655751d1bfb0f620139020a3a271973c22dbace4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f064a7e89c7a177630ba13411c0ed56c46e5b064"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "806b5ac90bdc9b8dce817b939a9a6cf38241b359"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "07094f93196367f8071ddd8e8541c6a3a60189ef"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "55607ab84ce16015366a047705f46c6f21ee2f71"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "743ffbacde7837603bb5bcf0686f5ea07fb0672e"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "71cdf30cce7331ed6356c67b8137ae45de8cc4c5"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "31447c1e4392f65ffbdd78930c2ff4e3c3f05454"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "362e7e348954d8914b014e8f788147d16f806f90"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "30d792475f2a7573a666d15c1e595a22f532b988"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "729145c6a8ef30eadd27ed487343315373a5938d"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ba331683cbfb908c243a90082d46ae6c637e7726"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b1042ef8494368ca4c4ae4c972e195bc97e490a5"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "89ed6ce052b9126ab02675653b381510e1407e82"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7ad692a695016d933b1e03a8061c0173db5c459b"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dc8845d1a0a4860a6be08205b4208dda51eeccd7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ea450b7e4d04dda4cadff6e62b7f7776af1d12da"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ab7ad1ab067328c2ba72187274ef3465a20e20e8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ac5cc0b133da05b02bbb3f1b218e257d2bbe5173"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "185c649f140073e210930416b23bbaaa8bfe4be7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bca9da41f4cb85e91a5ceaa6a1ab3193a285f013"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cfc135b5f9c7bf5140277cafc9f00d50ac8deac8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c179663a6385038dd87d7ae7a12c663a0e0037fa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "30e3d948d3b26d47654764b0048c2119b7b9f20b"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
